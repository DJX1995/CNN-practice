{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"data.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[\"image\"].astype('float32')\n",
    "X_train = (X_train/128.0 - 1.0)\n",
    "y_train = data[\"label\"].astype('int32')\n",
    "y_train = np.eye(4)[y_train].squeeze(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (20780, 32, 32, 3) , labels: (20780, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data:\",X_train.shape,\", labels:\",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_data:\n",
    "    def __init__(self, data_x, data_y, batch_size):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.batch_size = batch_size\n",
    "        self.index = 0\n",
    "        self.batch_x = []\n",
    "        self.batch_y = []\n",
    "        self.batch_number = int(self.data_x.shape[0] / self.batch_size)\n",
    "        for i in range(self.batch_number):\n",
    "            self.batch_x.append(self.data_x[i*self.batch_size:(i+1)*self.batch_size])\n",
    "            self.batch_y.append(self.data_y[i*self.batch_size:(i+1)*self.batch_size])\n",
    "            \n",
    "    def next_batch(self):\n",
    "        self.index = (self.index+1) % self.batch_number\n",
    "        return self.batch_x[self.index], self.batch_y[self.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = input_data(X_train, y_train, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_batch.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, [1,1,1,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpooling(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input_x, filter_shape):\n",
    "    W = init_weight(shape=filter_shape)\n",
    "    b = init_bias(shape=[filter_shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(input_x, hidden_nodes):\n",
    "    layer_shape = [int(input_x.get_shape()[1]),hidden_nodes]\n",
    "    W = init_weight(layer_shape)\n",
    "    b = init_bias([hidden_nodes])\n",
    "    return tf.matmul(input_x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_x = tf.placeholder(dtype=tf.float32, shape=[None,32,32,3])\n",
    "input_y = tf.placeholder(dtype=tf.int32, shape=[None,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv10 = conv_layer(input_x, [3,3,3,32])\n",
    "conv11 = conv_layer(conv10, [3,3,32,32])\n",
    "max_pool1 = maxpooling(conv11)\n",
    "conv20 = conv_layer(max_pool1, [3,3,32,32])\n",
    "conv20 = conv_layer(max_pool1, [3,3,32,32])\n",
    "max_pool2 = maxpooling(conv20)\n",
    "\n",
    "conv2_flat = tf.reshape(max_pool2, [-1,32//4 * 32//4 * 32])\n",
    "fc1 = tf.nn.relu(fc_layer(conv2_flat, 128))\n",
    "\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "fc_dropout = tf.nn.dropout(fc1,keep_prob=hold_prob)\n",
    "\n",
    "pred_y = fc_layer(fc_dropout, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=input_y, logits=pred_y))\n",
    "tf_pred = tf.nn.softmax(pred_y)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "tf_acc = tf.reduce_mean(tf.to_float(tf.equal(tf.argmax(tf_pred, 1), tf.argmax(input_y, 1))))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 32, 32, 3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x, batch_y = train_batch.next_batch()\n",
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "0.2454283\n",
      "Currently on step 100\n",
      "0.62993264\n",
      "Currently on step 200\n",
      "0.7078922\n",
      "Currently on step 300\n",
      "0.7475938\n",
      "Currently on step 400\n",
      "0.76997113\n",
      "Currently on step 500\n",
      "0.77333975\n",
      "Currently on step 600\n",
      "0.7836862\n",
      "Currently on step 700\n",
      "0.80365735\n",
      "Currently on step 800\n",
      "0.7846487\n",
      "Currently on step 900\n",
      "0.79956686\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "steps = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_x, batch_y = train_batch.next_batch()\n",
    "\n",
    "        sess.run(optimizer,feed_dict={input_x:batch_x,input_y:batch_y,hold_prob:0.5})\n",
    "        \n",
    "        #PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            print('Currently on step {}'.format(i))\n",
    "            acc = sess.run(tf_acc,feed_dict={input_x:X_val,input_y:y_val,hold_prob:1.0})\n",
    "            print(acc)\n",
    "            \n",
    "    print('Finish!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
